{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Cell_1_1:imports\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### **PART1**\n",
    "Update Dataset and save new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Cell_1_2:unit test-part1\n",
    "\n",
    "\n",
    "def df_equal(df1, df2):\n",
    "    \"\"\"\n",
    "    :param df1: pandas dataframe object\n",
    "    :param df2: pandas dataframe object\n",
    "    :return: True if all elements equel, False otherwise(bool)\n",
    "    \"\"\"\n",
    "    return (df1 == df2).to_numpy().all()\n",
    "\n",
    "\n",
    "def check_for_null_and_nan(df):\n",
    "    \"\"\"\n",
    "    :param df: pandas dataframe object\n",
    "    :return: if there any None of NaN values\n",
    "    \"\"\"\n",
    "    return not (df.isnull().to_numpy().any() or\n",
    "                df.isna().to_numpy().any())\n",
    "\n",
    "\n",
    "def test_updated_df(old, new):\n",
    "    \"\"\"\n",
    "    Assert if for old data unchanged and for no null/nan values\n",
    "    :param old:pandas DataFrame object before change \n",
    "    :param new:pandas DataFrame object after change \n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    assert len(old) == len(new)\n",
    "    assert df_equal(new[old.columns], old)\n",
    "    assert check_for_null_and_nan(new)\n",
    "\n",
    "\n",
    "def test_new_hotels_file(path, hotels_data):\n",
    "    \"\"\"\n",
    "    Asserts no data loss on file save\n",
    "    :param path: file relative path (string)\n",
    "    :param hotels_data: \n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    assert (pd.read_csv(path) == hotels_data).to_numpy().all()\n",
    "\n",
    "\n",
    "def test_update_function_values(update_func):\n",
    "    \"\"\"\n",
    "    Asserts correctness of the update function on dummy data\n",
    "    :param update_func: function for data update\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dummy_data = {\n",
    "        \"Snapshot Date\": [\"7/20/2015 0:00\"],\n",
    "        \"Checkin Date\": [\"7/21/2015 0:00\"],\n",
    "        \"Original Price\": [1000],\n",
    "        \"Discount Price\": [800]\n",
    "    }\n",
    "\n",
    "    result = update_func(pd.DataFrame(dummy_data))\n",
    "\n",
    "    assert (result[\"DayDiff\"] == 1).all()\n",
    "    assert (result[\"WeekDay\"] == 3).all()\n",
    "    assert (result[\"DiscountDiff\"] == 200).all()\n",
    "    assert (result[\"DiscountPerc\"] == 20.0000).all()\n",
    "\n",
    "\n",
    "def run_test1(path, update_func,updated_hotels):\n",
    "    \"\"\"\n",
    "    Run unit test on data\n",
    "    :param path: relative path to csv file\n",
    "    :param update_func:function for data update\n",
    "    :return: \n",
    "    \"\"\"\n",
    "\n",
    "    test_update_function_values(update_func)\n",
    "\n",
    "    \n",
    "\n",
    "    test_updated_df(hotels, updated_hotels)\n",
    "\n",
    "    test_new_hotels_file(path, updated_hotels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Cell_1_3:update and save anew file\n",
    "\n",
    "def update_hotel_data(df):\n",
    "    #day diff saved as int\n",
    "    df[\"DayDiff\"] = (pd.to_datetime(df[\"Checkin Date\"]) - pd.to_datetime(df[\"Snapshot Date\"])).dt.days\n",
    "\n",
    "    #save the weekday as int(1-7)\n",
    "    df[\"WeekDay\"] = (pd.to_datetime(df[\"Checkin Date\"]).dt.dayofweek + 2) % 7\n",
    "\n",
    "    #save the discaount diff \n",
    "    df[\"DiscountDiff\"] = df[\"Original Price\"] - df[\"Discount Price\"]\n",
    "\n",
    "    #save the discount percentage\n",
    "    df[\"DiscountPerc\"] = np.around(100 * df[\"DiscountDiff\"] / df[\"Original Price\"], 4)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#update and save\n",
    "hotels = pd.read_csv(\"hotels_data.csv\")\n",
    "updated_hotels = update_hotel_data(hotels)\n",
    "updated_hotels.to_csv(\"./hotels_data_changed.csv\", index=False)\n",
    "\n",
    "\n",
    "run_test1(\"./hotels_data_changed.csv\",update_hotel_data,updated_hotels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### **PART 2**\n",
    "Naive Bayes and Descision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Cell_2_1:unit test for data preparation\n",
    "\n",
    "#test helper function\n",
    "def test_data_preparation(prepare_train):\n",
    "    \"\"\"\n",
    "    The functiom assert correct data transformation on dummy daya\n",
    "    :param1:data_trandform a function\n",
    "    :return:None\n",
    "    \"\"\"\n",
    "    dummy = pd.DataFrame({\n",
    "        \"Snapshot Date\": [\"7/20/2015 0:00\", \"8/20/2015 0:00\", \"8/20/2015 0:00\"],\n",
    "        \"Checkin Date\": [\"7/21/2015 0:00\", \"8/21/2015 0:00\", \"8/21/2015 0:00\"],\n",
    "        \"Hotel Name\": [\"Hotel1\", \"Hotel2\", \"Hotel2\"],\n",
    "        \"DayDiff\": [1, 1, 1],\n",
    "        \"WeekDay\": [3, 4, 4],\n",
    "        \"DiscountPerc\": [10, 20, 5],\n",
    "\n",
    "    })\n",
    "\n",
    "    transformd = pd.DataFrame({\n",
    "        \"Snapshot Date\": [0, 31],\n",
    "        \"Checkin Date\": [0, 31],\n",
    "        \"Hotel Name\": [0, 1],\n",
    "        \"DayDiff\": [1, 1],\n",
    "        \"WeekDay\": [3, 4],\n",
    "        \"DiscountPerc\": [10, 20]\n",
    "\n",
    "    })\n",
    "\n",
    "    #use function from cell2\n",
    "\n",
    "    assert df_equal(prepare_train(dummy), transformd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Cell_2_2:data preparation fro training\n",
    "\n",
    "def get_max_groupd_by(df, group_cols, max_col):\n",
    "    \"\"\" \n",
    "    The functon group dataframe by given columns and get maximum  \n",
    "    of a given additional column per group.\n",
    "    :param df: pandas DataFrame object\n",
    "    :param group_cols: column names (list of strings )\n",
    "    :param max_col: column name (string)\n",
    "    :return:Grouped pandas DataFrame object\n",
    "    \"\"\"\n",
    "    return df.loc[df.groupby(group_cols)[max_col].idxmax()]\n",
    "\n",
    "\n",
    "def transform_date(col):\n",
    "    \"\"\" \n",
    "    Convert date value foro integer as days passed from first date.\n",
    "    Used with df.apply().\n",
    "    :param col: column name (str) representing string date values\n",
    "    :return:days passed from minimal date (int).\n",
    "    \"\"\"\n",
    "    new_col =pd.to_datetime(col)\n",
    "    return (new_col - min(new_col)).dt.days\n",
    "\n",
    "\n",
    "def col_to_labels(df, col_name):\n",
    "    \"\"\"\n",
    "    Get integer labels from column\n",
    "    :param df: pandas DataFrame object\n",
    "    :param col_name:the name of the column (int)\n",
    "    :return:list of integer labels (list of int)\n",
    "    \"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    col = df[col_name]\n",
    "    le.fit(col)\n",
    "    return le.transform(col)\n",
    "\n",
    "\n",
    "#prepare data for training\n",
    "def prepare_train_data(df):\n",
    "    #get the rows with max discount percentage per group\n",
    "    df = get_max_groupd_by(df, [\"Snapshot Date\", \"Checkin Date\", \"DayDiff\", \"Hotel Name\", \"WeekDay\"], \"DiscountPerc\")\n",
    "\n",
    "    #convert names to integer labels\n",
    "    df[\"Hotel Name\"] = col_to_labels(df, \"Hotel Name\")\n",
    "\n",
    "    #update date values to integers\n",
    "    df[[\"Snapshot Date\", \"Checkin Date\"]] = df[[\"Snapshot Date\", \"Checkin Date\"]].apply(transform_date)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#test preparation function and save\n",
    "test_data_preparation(prepare_train_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Cell_2_3:define metrics and prepare data\n",
    "\n",
    "def check_accuracy(clf, x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Fit the training data into a classifier and print number of mislabeled \n",
    "    examples and accuracy rate. \n",
    "    :param clf: classifier\n",
    "    :param x_train:training examples,array of shape (n_examples,n_features)\n",
    "    :param y_train:training labels,array of shape (n_examples)\n",
    "    :param x_test:test examples,array of shape (n_examples,n_features)\n",
    "    :param y_test:test labels,array of shape (n_examples)\n",
    "    :return:None (print accuracy)\n",
    "    \"\"\"\n",
    "    y_pred = clf.fit(x_train, y_train).predict(x_test)\n",
    "    print(f\"Accuracy for {clf} classifier:\")\n",
    "    print(f\"Number of mislabeled points out of a total {x_test.shape[0]} points : {(y_test != y_pred).sum()}\")\n",
    "    print(f\"Accuracy={round((1 - (y_test != y_pred).sum() / x_test.shape[0]) * 100, 2)}%\")\n",
    "\n",
    "\n",
    "def plot_multiclass_roc(clf, x_train, y_train, x_test, y_test, classes=(1, 2, 3, 4)):\n",
    "    \"\"\"\n",
    "    plot a roc curve for every class\n",
    "    :param clf: classifier\n",
    "    :param x_train:training examples,array of shape (n_examples,n_features)\n",
    "    :param y_train:training labels,array of shape (n_examples)\n",
    "    :param x_test:test examples,array of shape (n_examples,n_features)\n",
    "    :param y_test:test labels,array of shape (n_examples)\n",
    "    :param classes:array\n",
    "    :return:None (create a plot)\n",
    "    \"\"\"\n",
    "    #init roc comp dict\n",
    "    n_classes = len(classes)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    #predict probabilities using the classifier\n",
    "    y_pred = clf.fit(x_train, y_train).predict_proba(x_test)\n",
    "    # use binary labels (no multiclass support)\n",
    "    y_test = label_binarize(y_test, classes=classes)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = np.nan_to_num(roc_curve(y_test[:, i], y_pred[:, i]), 0)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    lw = 2\n",
    "\n",
    "    # aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # average and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure()\n",
    "    plt.plot(\n",
    "        fpr[\"micro\"],\n",
    "        tpr[\"micro\"],\n",
    "        label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "        color=\"deeppink\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        fpr[\"macro\"],\n",
    "        tpr[\"macro\"],\n",
    "        label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "        color=\"navy\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(\n",
    "            fpr[i],\n",
    "            tpr[i],\n",
    "            color=color,\n",
    "            lw=lw,\n",
    "            label=\"ROC curve DiscountCode: {0} (area = {1:0.2f})\".format(i + 1, roc_auc[i]),\n",
    "        )\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"FP Rate\")\n",
    "    plt.ylabel(\"TP Rate\")\n",
    "    plt.title(f\"Multiclass ROC plot for {clf}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "hotels = pd.read_csv(\"./hotels_data_changed.csv\")\n",
    "\n",
    "#prepare data for learning\n",
    "hotels = prepare_train_data(hotels)\n",
    "\n",
    "#get \n",
    "X = hotels[[\"Snapshot Date\", \"Checkin Date\", \"DayDiff\", \"Hotel Name\", \"WeekDay\"]].to_numpy()\n",
    "\n",
    "y = hotels[\"Discount Code\"].to_numpy()\n",
    "\n",
    "#create training data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Cell_2_4:run and test GaussianNB\n",
    "nbgc = GaussianNB()\n",
    "check_accuracy(nbgc, x_train, y_train, x_test, y_test)\n",
    "plot_multiclass_roc(nbgc, x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Cell_2_5:run and test CategoricalNB\n",
    "nbcc = CategoricalNB()\n",
    "check_accuracy(nbcc, x_train, y_train, x_test, y_test)\n",
    "plot_multiclass_roc(nbcc, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Cell_2_6:run and test Decision Tree Classifier\n",
    "dtc = DecisionTreeClassifier(random_state=0, criterion='gini')\n",
    "check_accuracy(dtc, x_train, y_train, x_test, y_test)\n",
    "plot_multiclass_roc(dtc, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "#### conclusions-part 2\n",
    "\n",
    "The data fitted into 3 classifiers: 2 types of Naive Bayes Classifier\n",
    "and one Decision Tree classifier.\n",
    "\n",
    "*The data was transformed allowing string(dates and name) variables to be fitted.\n",
    "Few alternative transformation was considered (like day-month only date variable to capture periodicity)\n",
    " with no increase in performance.\n",
    "\n",
    "\n",
    "**Naive Bayes classifier** perform poorly on the data set.\n",
    "The **Gaussian NB classifier** perform only slightly better than a random selection with around 30% accuracy on the data set.\n",
    "The ROC plot shows  AUC of 0.55, again very close to 1/2 of a random choice,the result shown here:\n",
    "\n",
    "![Naive Bayes classifier](images/nbgc.png)\n",
    "\n",
    "\n",
    "Naive Bayes failure may not be surprise as it assumes variable independence which may not accuse here (pricing policy may depend on the hotel,week-day derived from checkin date), also most of the variables don't correspond to gaussian(normal) distribution (Checkin Date do show some correspondence)\n",
    "Distributions shown here:\n",
    "\n",
    "![Hotel Name Dist](images/hotel_name_dist.png)![Snapshot Date Dist](images/snapshot_date_dist.png)![Checkin Date Dist](images/checkin_date_dist.png)![Weekday Dist](images/week_day_dist.png)![Day Diff Dist](images/day_diff_dist.png)\n",
    "\n",
    "\n",
    "**Categorical NB classifier** perform slightly better around 43% accuracy and with AUC of around 0.7 as shown here:\n",
    "\n",
    "![Categorical NB classifier](images/nbcc.png)\n",
    "\n",
    "The categorical classifier fit slightly better as the categorical distribution (generalized Bernoulli) may fit some of the variables better.\n",
    "\n",
    "**Decision Tree Classifier** perform better at 78% accuracy and AUC of 0.85 which may be suitable for some applications:\n",
    "\n",
    "![Decision Tree Classifier](images/dtc.png)\n",
    "\n",
    "Decision Tree perform better arguebly because it can learn variable dependancies in contrast to NB.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **PART 3**\n",
    "Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Cell_3_1:create hotels -prices dataframe\n",
    "\n",
    "def get_first_groupd_by(df, group_cols, first_col):\n",
    "    \"\"\" \n",
    "    The functon group dataframe by given columns and get the \n",
    "    first entry  of a given additional column per group.\n",
    "    :param df: pandas DataFrame object\n",
    "    :param group_cols: column names (list of strings )\n",
    "    :param first_col: column name (string)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return df.loc[df.groupby(group_cols)[first_col].first()]\n",
    "\n",
    "\n",
    "def get_most_frequent_values(df, col_name, n):\n",
    "    \"\"\" \n",
    "    The function find the n most frequent values by column\n",
    "    :param df: pandas DataFrame object\n",
    "    :param col_name: The name of the column (string)\n",
    "    :n: number of elements (int)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return df[col_name].value_counts().index.to_numpy()[:n]\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"hotels_data.csv\")\n",
    "\n",
    "#find 150 most frequent hotels\n",
    "#sorting ensures alphabetic order\n",
    "hotel_names = np.sort(get_most_frequent_values(df, \"Hotel Name\", 150))\n",
    "\n",
    "#update df by hotels and chekin dates\n",
    "df = df.loc[df[\"Hotel Name\"].isin(hotel_names)]\n",
    "\n",
    "assert len(df[\"Hotel Name\"].unique()) == 150\n",
    "\n",
    "#find 40 most frequent checkin dates and update\n",
    "checkin_dates = get_most_frequent_values(df, \"Checkin Date\", 40)\n",
    "df = df.loc[df[\"Checkin Date\"].isin(checkin_dates)]\n",
    "\n",
    "assert (len(df[\"Checkin Date\"].unique())) == 40\n",
    "\n",
    "#get only the relevant columns\n",
    "df = df[[\"Hotel Name\", \"Checkin Date\", \"Discount Code\", \"Discount Price\"]]\n",
    "\n",
    "#get max value of discount price for consistency and group by relevant values\n",
    "#maximum value chosen as a consistency point, random value like first may work as well.\n",
    "df = get_max_groupd_by(df, [\"Hotel Name\", \"Checkin Date\", \"Discount Code\"], \"Discount Price\")\n",
    "\n",
    "\n",
    "\n",
    "#normalize for [0,100] range\n",
    "df[\"Discount Price\"] = 100 * df[\"Discount Price\"] / df[\"Discount Price\"].max()\n",
    "\n",
    "#ensures hotel alphabetic order\n",
    "df.sort_values([\"Hotel Name\"], ascending=True)\n",
    "\n",
    "#create a dict for full range of possible values\n",
    "hotels_dict = {\"Hotel Name\": hotel_names}\n",
    "for i in range(1, 5):\n",
    "    for date in checkin_dates:\n",
    "        #mark every checkin date-key with discount code\n",
    "        hotels_dict[f\"{date}-{i}\"] = []\n",
    "\n",
    "    #fill the dictionary values iterating original df rows\n",
    "for row in df.iterrows():\n",
    "    name, date, code, price = row[1]\n",
    "    hotels_dict[f\"{date}-{code}\"].append(price)\n",
    "\n",
    "#creating hotels df with missing values as NaN\n",
    "hotels = pd.DataFrame({key: pd.Series(value) for key, value in hotels_dict.items()})\n",
    "\n",
    "#fill the missing values with -1\n",
    "hotels = hotels.fillna(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Cell_3_2:run clustering\n",
    "\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "X = hotels.drop([\"Hotel Name\"], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# finding the optimal number of clusters using dendrogram\n",
    "dendrogram = sch.dendrogram(sch.linkage(X, method='ward'))\n",
    "\n",
    "plt.title('Hotels Dendrogram')  # title of the dendrogram\n",
    "plt.xlabel('Hotels')  # label of the x-axis\n",
    "plt.ylabel('Euclidean distances')  # label of the y-axis\n",
    "plt.show()  # show the dendrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### conclusions-part 3\n",
    "\n",
    "The dendrogram shown here:\n",
    "![Decision Tree Classifier](images/dendogram.png)\n",
    "\n",
    "Ward method(minimum variance) used.\n",
    "From the dendrogram we can assert the number of clusters:\n",
    "Using horizontal cut we can assert 2 bigger clusters (distant more then a half way from each other) and maybe 2-3 evident subclasters for each of the bigger.\n",
    "\n",
    "It may correspond to number of start or other hotel clusters (luxury vs regular hotels).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23e7a0b0a1ade771721f510eeefb26c42b77578caec684a32e14f7e5228bf389"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
